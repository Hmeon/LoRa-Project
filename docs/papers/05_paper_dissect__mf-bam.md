<!--
Suggested filename:
  docs/papers/mf-bam_2023_deconstruction.md
-->

# Paper Deconstruction (Project-Aligned): MF-BAM (Neural Networks, 2023)

## Paper identity (for traceability)
- **Model name**: MF-BAM (Multi-Feature extracting bidirectional associative memory - Bidirectional Associative Memory)
- **Core idea in one sentence (paper's own internal framing)**: Use a **stack of unsupervised FEBAM-based layers** to progressively generate a hidden representation that is (ideally) **linearly separable**, so that a final supervised BAM layer can reliably learn **input-target hetero-associations** with homogeneous internal mechanisms (same local learning + transmission function across layers).  
- **Scope of this note**: This document does **not** compare MF-BAM to other compression/ML approaches; it only reconstructs the *paper's internal logic* into design-relevant "building blocks" that can be instantiated in an IoT/LoRa compression project.

---

## 0) Notation and entities (as defined by the paper)

| Symbol | Meaning |
|---|---|
| `p` | Input pattern |
| `o` | Output target |
| `h1, h2, ..., hl` | Hidden representations generated by each UL |
| `UL` | Unsupervised Layer (FEBAM-based subnetwork) |
| `SL` | Supervised Layer (modified BAM) |
| `u` | # units per UL in the MF module (architectural parameter) |
| `l` | # unsupervised layers in the MF module (architectural parameter) |
| `delta` | Transmission-function parameter |
| `eta` | Learning parameter |
| `c` | Iteration cycle index (cycles before updating weights) |
| `e` | Epoch (training time budget; stopping condition) |
| `P` | List of all input patterns `p` |
| `HO` | List of pairs `(hl, o)` produced by the last UL and their targets |

> This matters for our project because MF-BAM is expressed as a **pattern-to-pattern association machine**: the only way it "means compression" is by how we instantiate `(p, o)` and which internal representation we choose to transmit/store.

---

## 1) Research problem: how the paper formalizes it

### 1.1 The "failure condition" the paper starts from
The paper frames nonlinear task learning as a problem where a downstream associative memory (BAM) will succeed **only if** the representation it receives makes the task **linearly separable**. If the MF component *fails* to create such a representation, "the outputted behavior of the MF-BAM will be linear, and the model will fail."  

### 1.2 The target capability being tested
The paper's research question is operationalized as:

> Can a recurrent neural associative memory with homogeneous internal rules **consistently** learn **nonlinear tasks**, by generating hidden representations through a multi-layer unsupervised component, then associating those representations to targets with a supervised BAM?

Concretely, the evaluation suite is built around **nonlinear problems** (parity + Moons/Eclipse/Suns), plus **continuous online learning** and **multiclass** behavior (3-class spiral). All are presented as **hetero-association** tasks: learn input-target pairs.

### 1.3 What the model is "supposed to do" in the paper's logic
- The MF component is treated as a *representation generator*.
- The SL (BAM) component is treated as an *associator* that learns mapping between generated representation and target.
- Therefore, the paper's success criterion is not "compression ratio," but:  
  **Does MF produce a stable `hl` representation such that BAM can learn the association reliably (low MSE, good recall)?**

---

## 2) "Limits of existing approaches" as assumed inside the paper's argument

This section is *not* a survey; it is the **minimal set of premises** the paper uses to justify MF-BAM.

### 2.1 Standard problem: nonlinear relationships break simple association
The paper's internal premise is: if the relationship between inputs and targets is nonlinear (linearly inseparable), a single-stage associative mechanism will not reliably solve it unless the representation is changed.

### 2.2 The "design flaw" motivating MF-BAM (from the paper's narrative)
The paper describes a prior multi-FEBAM idea where each FEBAM subnetwork had to be trained **sequentially in isolation** (first finishes learning, then second begins), which is "highly successful" for decorrelation but introduces a practical/architectural flaw: training time and coordination increase because each layer must receive constant information until it stabilizes.

MF-BAM is then positioned as a fix: keep multi-FEBAM power while avoiding the strict "train each layer in isolation" requirement via a head-to-toe organization where learning "trickles down" once earlier layers stabilize.

### 2.3 Cognitive plausibility as a constraint (not optional in this paper)
A key internal constraint is that the model should be a *recurrent neural associative memory* with **homogeneous internal mechanisms** (same learning rule + transmission function across layers), i.e., not a heterogeneous "add modules until it works" system.

---

## 3) Proposed method: pipeline structure (paper's actual computational graph)

### 3.1 High-level architecture
MF-BAM consists of:
1) **MF module**: multiple unsupervised layers `UL1..ULl` based on FEBAM  
2) **BAM module (SL)**: one supervised layer (modified BAM)

The operational sequence for one pattern is:

1. Present input pattern `p` to `UL1`
2. `UL1` learns/generates `h1`
3. Pass `h1` to `UL2`, which learns/generates `h2`
4. Repeat until deepest representation `hl` is produced
5. Feed `hl` to the supervised BAM layer (`SL`) to learn association `hl <-> o`

### 3.2 "Bidirectional" behavior (important for compression-style instantiations)
The paper explicitly emphasizes that once trained:
- Presenting `A` to MF-BAM generates the hidden representations and the desired output `B`.
- Because it is bidirectional, giving `B` to the output layer of the SL can retrieve hidden representations and reconstruct `A` at the input of `UL1`.

This is the key internal mechanism that makes MF-BAM relevant to any "compress/restore" narrative: it already treats the learned mapping as an **invertible associative process**, insofar as the training pairs and learned dynamics support that.

### 3.3 Learning organization ("trickle-down stabilization")
The paper's logic relies on the idea that each FEBAM-based UL stabilizes as it receives constant information; as earlier layers produce stable outputs, deeper layers can begin producing stable solutions, eventually stabilizing the last layer `hl`. This is how MF-BAM claims to avoid having to fully train each layer in complete isolation while keeping the same internal mechanisms.

---

## 4) Assumptions required for the paper's method to hold

These are not "real-world assumptions," but the assumptions *the paper's internal argument depends on*.

### 4.1 Representation assumption (the central one)
**MF must transform the task**: nonlinear input-target relations are progressively transformed into a **linearly separable** representation at the last UL. If this holds, the paper claims the BAM layer "should easily be able to learn the task"; otherwise, MF-BAM fails.

### 4.2 Stabilization assumption (dynamics must settle)
Learning depends on ULs receiving **constant information** long enough to stabilize to weight values that produce a stable `hl` pattern. The pipeline assumes this stabilization can occur repeatedly across UL depth.

### 4.3 Homogeneity assumption (same internal mechanisms across layers)
The paper constrains itself to homogeneous internal mechanisms (local learning + same transmission function, bidirectional structure) rather than specialized per-layer changes.

### 4.4 Task framing assumption: hetero-association is the canonical interface
All evaluated problems are framed as **hetero-association**: the model is always asked to learn input-target pairs. This is important: the paper's meaning of success is always "learn the mapping between two pattern spaces," not "minimize reconstruction loss of the input under bitrate constraints."

### 4.5 Parameter boundedness assumption
The paper fixes `delta` and constrains `eta` (and other training settings) across simulations, treating them as stable global settings while it varies the structural parameters `u` and `l`.

---

## 5) Experimental design logic and the paper's fixed conditions

This section reconstructs the paper's "why this experiment suite answers the question."

### 5.1 Why these tasks?
The paper chooses a progression of nonlinear tasks and behaviors to test whether MF-BAM:
- solves binary nonlinear mapping (parity),
- handles continuous nonlinear decision boundaries (Moons/Eclipse/Suns),
- maintains learning under ongoing arrivals of new patterns (continuous online learning),
- handles multiclass nonlinear structure (3-class spiral).

All remain within the same hetero-association interface.

### 5.2 Fixed training protocol (global constants)
Across simulations, the paper keeps the learning/recall procedure identical and fixes/standardizes:
- Transmission parameter `delta` (set to a constant in the general methodology).
- Learning parameter `eta` constrained to a stability range (`0 < eta < 1/max(m,n)`).
- Bias neurons at every input layer initialized to 1.
- Weight initialization: uniform in a small range (e.g., -0.1 to 0.1).
- Cycles before updates: `c = 1`.
- Stopping condition: training stops at maximum epochs `e` per simulation condition.
- Implementation context: Python (Anaconda), with reported GPU hardware.

### 5.3 Measurements (why these metrics)
The paper uses three measurements to capture complementary failure modes:

1) **Learning error (MSE)**
- For MF: difference between generated patterns at cycle `c` and `c-1` (stability of representation).
- For BAM: difference between predicted output and target (association correctness).
- Low MSE is interpreted as both "stable hidden representation" and "successful association."

2) **Decision zones** (only for 2D input tasks)
- The paper maps the 2D input space densely (from [-1,-1] to [1,1]) to visualize the learned classification behavior.
- It frames this as analogous to train-test split evaluation: test on novel instances.

3) **Recall performance**
- Directly measures whether learned associations are retrievable.

### 5.4 Structural manipulation logic (the core experimental lever)
The paper treats two structural parameters as the primary levers:
- `u`: number of units per UL
- `l`: number of ULs in the MF module

It argues that (given layered biological inspiration) these are the structural choices that should impact behavior, and tests them systematically. It also introduces a "learning time budget" lever:
- constrain MF learning time (`e`) while keeping BAM training time constant in some sections, to separate "representation formation" from "association training."

---

## 6) Expandable design axes (what the paper shows you can vary *within its own framework*)

This is a "design space map" strictly bounded by what the paper manipulates or defines as parameters.

### 6.1 Structural axes (explicitly manipulated)
1) **`u` (units per UL)**  
   Affects the capacity/shape of representations generated at each UL.

2) **`l` (number of ULs)**  
   Affects the number of transformations from `p` to `hl` (depth of representation generation).

3) **Interaction of `u x l` under limited MF learning time `e`**  
   The paper explicitly studies how the best `u/l` region depends on the learning time available for MF to stabilize, while BAM is held constant.

### 6.2 Training-time axis (explicitly manipulated)
- **MF learning time budget (`e`)**  
  The paper constrains MF learning time (e.g., small vs large) to test when deeper/larger architectures help or hurt under time constraints.

### 6.3 Global mechanism parameters (fixed in the paper, but still part of the formal model)
Even though the paper fixes these during experiments, they remain formal parameters:
- Transmission function parameter `delta`
- Learning parameter `eta` (bounded by a constraint)
- Update cycle count `c`
- Weight init range / bias handling

### 6.4 Task/interface axis (implicit but fundamental)
- **Definition of what `(p, o)` means**  
  The paper always uses hetero-association tasks; within the same framework, changing what constitutes "target pattern `o`" changes the learned function class.

---

## 7) Assumptions likely to break when instantiated in a real LoRa sensor-compression project

This section stays inside the paper's logic, but flags where *the paper's own prerequisites* are most fragile when the "patterns" come from real sensor streams and the system is deployed.

### 7.1 Fragile assumption: "MF produces linearly separable `hl`"
In the paper, MF-BAM succeeds if the final representation is linearly separable (so BAM can learn the mapping easily). In an IoT sensor setting, this becomes a strong requirement on:
- how sensor windows are vectorized into `p`,
- whether the variability/noise/nonstationarity of sensors still allows MF to stabilize into a representation where targets are separable.

If separability fails, the paper's own condition says MF-BAM fails (behavior becomes effectively linear).

### 7.2 Fragile assumption: constant-information stabilization
MF-BAM's UL stabilization logic assumes layers receive constant information long enough to stabilize and produce consistent `hl`. Real deployments introduce:
- drifting distributions (temperature regimes, motion modes),
- missing segments (packet loss upstream of training logs, sensor dropouts),
- timing irregularities.

Even if training is offline, online adaptation inherits this fragility: if the system is expected to "keep learning" from streaming data, the stabilization premise becomes operationally difficult.

### 7.3 Fragile assumption: the hetero-association interface matches "compression"
The paper's canonical interface is learning `(p, o)` pairs. "Compression" is not an intrinsic metric in the paper; it emerges only if we instantiate targets and usage such that:
- the model's bidirectionality is used as a reconstruction mechanism,
- the transmitted/stored object corresponds to either `hl` or `o`,
- and reconstruction corresponds to "retrieve `p` from the transmitted pattern."

If the project's operational requirement is "transmit fewer bytes but preserve information," the paper's framework forces a *design decision* about what is treated as `o` (target) and what is actually sent-otherwise the model is simply an associative learner, not a bitrate-aware compressor.

### 7.4 Fragile assumption: 2D decision-zone methodology doesn't generalize as a diagnostic
The paper's decision-zone evaluation is explicitly tied to 2D input vectors (grid sampling in [-1,1]^2). Sensor windows (GPS+IMU+attitude) are high-dimensional and time-dependent; the "decision zone" diagnostic cannot be used as-is.  
This doesn't refute MF-BAM; it just means one of the paper's key interpretability tools is unavailable in the target setting.

### 7.5 Fragile assumption: training-time sufficiency (MF needs time to stabilize)
The paper shows performance regions depend on MF learning time `e` when varying `u` and `l`. In embedded/edge contexts, training-time and compute budgets are constrained; if MF cannot be given adequate learning time to stabilize, the representation may never reach the conditions the paper relies on.

---

## 8) Project-aligned instantiation checklist (mapping MF-BAM to "sensor compression over LoRa" without leaving the paper's formalism)

> This is not a new method; it is a checklist for instantiating the paper's variables with our project objects.

### 8.1 Define the paper's "patterns" in project terms
- Define `p` (input pattern) as a *vectorized sensor window*.
  - Example categories (project-provided): GPS (lat, lon, alt), accelerometer (ax, ay, az), gyroscope (gx, gy, gz), attitude (roll, pitch, yaw).
- Define `o` (output target) explicitly, because MF-BAM learns hetero-association:
  - Option A (reconstruction-shaped): `o` is a representation designed so that feeding `o` back retrieves `p` (leveraging bidirectionality).
  - Option B (task-shaped): `o` is a label/semantic state; then reconstruction of raw sensor windows is not the goal-association is.

### 8.2 Decide which internal object is "the payload"
Within MF-BAM, there are three pattern spaces that could be treated as a transmit/store object:
- `hl` (deep hidden representation),
- `o` (target pattern),
- or both (depending on deployment constraints).

The paper explicitly describes a bidirectional retrieval path involving SL output and reconstructing UL1 input, but the exact "payload object" must be chosen by system design.

### 8.3 Treat `u`, `l`, `e` as the primary architectural control knobs
The paper's own experimental design treats:
- `u` and `l` as primary structural parameters,
- `e` (MF learning time) as a controlling factor for whether deeper/larger configurations help,
while holding core learning mechanisms fixed.

For our project's Design Doc, these become the first-class axes in the architecture matrix.

### 8.4 Keep the paper's stability/consistency criteria explicit
Because the paper uses "stable representation in MF" and "successful association in BAM" as distinct criteria (both via MSE), the project plan should also define:
- what "MF stability" means under sensor drift,
- what "association success" means for reconstruction/semantics,
- and how those are measured under packet loss / interference experiments.

---

## 9) One-page "paper logic summary" (for fast recall)

MF-BAM is a bidirectional associative architecture with:
- **UL stack (FEBAM-based)**: generates progressively transformed hidden representations `h1..hl` from an input pattern `p`.
- **SL (modified BAM)**: learns to associate `hl` with output target `o`.
- **Central success condition**: MF must produce `hl` that makes the mapping to `o` linearly separable; otherwise the model fails.
- **Key design knobs**: `u` (#units per UL), `l` (#UL layers), and MF learning-time budget `e` (with fixed delta, eta constraint, c=1, bias and weight init conventions).
- **Evaluation suite**: parity + continuous nonlinear tasks + online learning + multiclass spiral, assessed by MSE (stability + correctness), decision zones (2D only), and recall performance.

---

End of document.
